{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LimeTasteLife/2022ML_TP/blob/main/HW4/HW4_201820717_%EC%A3%BC%ED%95%98%EC%98%81.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **HW4 :: DNN**\n",
        "## 과제 목표\n",
        "* 간단한 Three Layer Network를 구현하기\n",
        "* Pytorch를 사용하여 DNN 구현 후 학습과 테스트하기\n",
        "  \n",
        "  \n",
        "   \n",
        "\n"
      ],
      "metadata": {
        "id": "EXvAS7OZkg_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭐  이번 과제는 bb에 코랩 링크, ipynb 파일만 업로드합니다(HW3와 동일하게).   \n",
        "⭐  작성한 코드에 **간단한 주석을 반드시 달아주세요**!  \n",
        "⭐  코딩할 부분을 제외하고는 수정하지 마세요. 수정 시 감점입니다."
      ],
      "metadata": {
        "id": "k5IhqPYwmnUv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **문제 1 - Three Layer Network**\n",
        "```class Sigmoid```와 ```Affine```을 구현한 후 이 두 class를 사용하여 ```class ThreeLayerNet```를 완성하세요. \n",
        "* 코드 참고 : deep learning from scratch"
      ],
      "metadata": {
        "id": "OKfJ8-LiFOr8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 1-1\n",
        "class sigmoid의 forward 함수를 구현하세요.  \n",
        "힌트) sigmoid 함수 식"
      ],
      "metadata": {
        "id": "FrrWMAJx6FUC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "QSI6QIBkCPWP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        self.params = []\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "      #############################################\n",
        "      ################### 문제 1-1 #################\n",
        "      ############# sigmoid forward 구현 ###########\n",
        "      #############################################\n",
        "        # 한 줄로 구현\n",
        "        result = 1 / (1 + np.exp(-x))\n",
        "        # sigmoid 식을 코드화시킨 것\n",
        "      #############################################\n",
        "      \n",
        "        return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 1-2\n",
        "class Affine의 forward 함수를 구현하세요.  \n",
        "힌트) affine 함수 식"
      ],
      "metadata": {
        "id": "1YcAkmtN6UXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Affine: # Affine은 Fully Connect를 의미합니다\n",
        "    def __init__(self, W, b):\n",
        "        self.params = [W, b]\n",
        "\n",
        "    def forward(self, x):\n",
        "      \n",
        "      #############################################\n",
        "      ################### 문제 1-2 #################\n",
        "      ############# affine forward 구현 ############\n",
        "      #############################################\n",
        "        # 코드 작성\n",
        "        input = x\n",
        "        out = np.dot(x, self.params[0]) + self.params[1]\n",
        "        # 행렬 연산을 코드화 시킨 것.\n",
        "      #############################################\n",
        "      \n",
        "        return out\n"
      ],
      "metadata": {
        "id": "Ds05drVvG5O_"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 1-3\n",
        "\n",
        "  각 layer의 parameter를 ```np.random.randn()``` 를 사용하여 초기화하세요.  \n",
        "  * 조건) ```class ThreeLayerNet```은 총 3개의 fully connected layer로 구성됩니다.\n",
        "  * 힌트) 차원을 잘 고려하세요. \n"
      ],
      "metadata": {
        "id": "aX3vaESK6jp_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 1-4\n",
        "  문제1-1, 2에서 구현한 class를 사용하여 ThreeLayerNet의 layer를 구성하세요.\n",
        "  * 조건) ```class ThreeLayerNet```은 총 3개의 fully connected layer로 구성됩니다.\n",
        "  * 힌트) 차원을 잘 고려하세요."
      ],
      "metadata": {
        "id": "qoPlnkHg_18J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ThreeLayerNet:\n",
        "    def __init__(self, input_size, first_hidden_size, second_hidden_size, output_size):\n",
        "        I, H_1, H_2,O = input_size, first_hidden_size, second_hidden_size, output_size\n",
        "\n",
        "      #############################################\n",
        "      ################### 문제 1-3 #################\n",
        "      ######### parameter initialization ##########\n",
        "      #############################################\n",
        "        # 코드 작성\n",
        "        self.W1 = np.random.randn(input_size, first_hidden_size)\n",
        "        self.b1 = np.random.randn(1, first_hidden_size)\n",
        "        self.W2 = np.random.randn(first_hidden_size, second_hidden_size)\n",
        "        self.b2 = np.random.randn(1, second_hidden_size)\n",
        "        self.W3 = np.random.randn(second_hidden_size, output_size)\n",
        "        self.b3 = np.random.randn(1, output_size)\n",
        "\n",
        "        # 각각 차원에 맞게 randn을 통해 W값과 b값 생성\n",
        "\n",
        "      #########################################\n",
        "        \n",
        "\n",
        "        self.layers = [\n",
        "        #############################################\n",
        "        ################### 문제 1-4 #################\n",
        "        ############### stack layers ################\n",
        "        #############################################          \n",
        "            # 코드 작성\n",
        "            Affine(self.W1, self.b1),\n",
        "            Sigmoid(),\n",
        "            Affine(self.W2, self.b2),\n",
        "            Sigmoid(),\n",
        "            Affine(self.W3, self.b3),\n",
        "\n",
        "            #layer stack을 만들어 둔다. 각 Layer 사이에는 activation이 필요하다.\n",
        "\n",
        "        #############################################    \n",
        "        ]\n",
        "\n",
        "        # 모든 weight 를 담은 리스트 생성\n",
        "        self.params = []\n",
        "        for layer in self.layers:\n",
        "            self.params += layer.params\n",
        "\n",
        "    def predict(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer.forward(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "VmHw4K5DG3uv"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dummy data로 모델 실행해보기\n",
        "x = np.random.randn(784, 100)\n",
        "model = ThreeLayerNet(100, 50, 30, 10)\n",
        "s = model.predict(x)\n",
        "print(s)"
      ],
      "metadata": {
        "id": "SNI0xGraFAAt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0822a4a0-ebb7-42ae-b5bb-136dc8763368"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3.43481205  1.28034144  6.5959879  ...  5.95178862  3.10552961\n",
            "  -1.04280416]\n",
            " [ 2.6631724   2.17277721  4.72134132 ...  5.56672099  1.52269859\n",
            "  -3.56110022]\n",
            " [ 2.28230323  0.22243553  5.44072238 ...  7.3202022  -2.86060699\n",
            "  -3.8956017 ]\n",
            " ...\n",
            " [ 2.83320044  1.44167066  4.65972182 ...  7.84131999  1.23743596\n",
            "  -3.49525536]\n",
            " [-0.81406307  2.90192461  2.55197473 ...  6.09140684 -1.21564238\n",
            "  -3.05597574]\n",
            " [ 2.73067822  0.37806716  2.95207338 ...  1.34325026 -0.97374655\n",
            "  -7.05407928]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "FtZZAx7vovt4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 문제 2 - Implementing DNN using Pytorch\n",
        "문제 1에서는 Pytorch를 사용하지 않고 DNN을 구현해보았습니다.  \n",
        "문제 2에서는 Pytorch를 사용하여 DNN을 구현하고 MNIST 데이터로 분류 모델 학습을 진행합니다.\n",
        "* 코드 참고: pytorch 공식 튜토리얼"
      ],
      "metadata": {
        "id": "hOzYC0u5GfkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 importing\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "LKcI43VULpeQ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load Data**"
      ],
      "metadata": {
        "id": "WCbWy3jAMGuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training data\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True, # training data\n",
        "    download=True,\n",
        "    transform=ToTensor() # 이미지를 tensor로 변형\n",
        ")\n",
        "\n",
        "# Load test data\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False, # test data\n",
        "    download=True,\n",
        "    transform=ToTensor() # 이미지를 tensor로 변형\n",
        ")\n",
        "\n",
        "# data loader\n",
        "# train, test 각각의 data loader 생성\n",
        "train_loader = torch.utils.data.DataLoader(training_data, batch_size=1, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)"
      ],
      "metadata": {
        "id": "D9DqIegtLnz9"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Check loaded data**\n",
        "train_loader를 사용하여 하나의 데이터를 로드한 후 이 데이터가 어떤 숫자의 데이터인지 이미지로 확인해봅니다."
      ],
      "metadata": {
        "id": "QtJVlNT9A_KK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train feature와 label을 train_loader로부터 가져오기\n",
        "train_features, train_labels = next(iter(train_loader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")"
      ],
      "metadata": {
        "id": "IF90dcyJPhVw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b9c2e91-50d4-4773-9a5c-a0b57ac7ff20"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([1, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지로 확인\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "id": "00Wypwb2Pr-r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "b5866921-1ff7-4c6f-a5ed-ac53bd039dd6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 2-1\n",
        "4개의 linear layer와 3개의 ReLU layer를 가진 네트워크를 구성하세요.\n",
        "\n"
      ],
      "metadata": {
        "id": "BB_Qe54pB8_S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 2-2\n",
        "forward 함수의 빈칸을 구현하세요."
      ],
      "metadata": {
        "id": "mK5ukeeECYJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten() # 28x28 이미지를 784 픽셀 값의 배열로 변경\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            \n",
        "            nn.Linear(in_features=28*28, out_features=512),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            #############################################\n",
        "            ################### 문제 2-1 #################\n",
        "            # 4개의 linear layer와 3개의 ReLU layer를 구성하세요\n",
        "            # (위 Linear 포함 4개, ReLU layer 포함 3개를 의미)\n",
        "            #############################################\n",
        "            \n",
        "            # 시작 차원, 끝 차원 잘 고려하여 작성하기\n",
        "            # 중간 차원은 임의로 설정 가능\n",
        "\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32 ,10)\n",
        "\n",
        "            # nn.Sequential의 method의 특징은 코드에 적힌 순서대로 값을 전달해준다.\n",
        "            # 위 Linear 포함해서 4개의 Linear layer, 3개의 ReLU로 구성했다.\n",
        "            # 정답은 10개의 클래스로 분류되어야 하기 때문에 마지막 차원이 10이다.\n",
        "            # 중간의 차원은 임의로 작성했다.\n",
        "            # 하지만 전의 Linear의 output이 다음 Linear의 input이 되어야함을 유의하자.\n",
        "\n",
        "            #############################################\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        #############################################\n",
        "        ################### 문제 2-2 #################\n",
        "        # forward 함수 구현\n",
        "        #############################################\n",
        "        # 코드 작성\n",
        "\n",
        "        x = x.float()\n",
        "        # 주어진 data x를 위에 정의된 network 연산을 거칩니다.\n",
        "        res = self.linear_relu_stack(x.view(-1, 784))\n",
        "        # 나온 결과 값을 확률로 해석합니다.\n",
        "        logits = nn.functional.log_softmax(res, dim=1)\n",
        "\n",
        "        #############################################\n",
        "        return logits # forward 결과 저장"
      ],
      "metadata": {
        "id": "zme9j_4hMiA2"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cpu OR gpu 설정\n",
        "# gpu가 있을 경우, device로 cuda를 사용함\n",
        "# colab에서 '런타임 유형 변경'을 하면 gpu 사용할 수 있음\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "id": "kfBLbfwUJgtP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "813a07c9-fc2c-4d5e-a60c-152be99bc64f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device) # device로 Network 전송\n",
        "print(model) # 모델 구조 확인"
      ],
      "metadata": {
        "id": "ifGukRqQOUyV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bacb91f4-c41a-47ba-f728-c81cd24149bd"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=128, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=128, out_features=32, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=32, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 앞에서 출력해보았던 train_features[0](1개의 데이터)에 대해서 모델 학습 결과 확인해보기\n",
        "logits = model(train_features[0]) # 일부 백그라운드 연산들과 함께 모델의 forward 를 실행 \n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ],
      "metadata": {
        "id": "MdOf0Rd1VEi9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2ad2b08-d67f-454d-a585-805d7ab6826a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train the Network** \n",
        "epoch과 batch를 활용하여 모델을 학습시켜 봅시다."
      ],
      "metadata": {
        "id": "J5G6rO77V7OR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 2-3\n",
        "모델의 forward, backward, optimize 하는 부분을 주어진 칸에 구현하세요."
      ],
      "metadata": {
        "id": "n7RwQwKDCjOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)"
      ],
      "metadata": {
        "id": "y7jdCHQphsIO"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameter 설정\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss() # loss function\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) # optimizer\n",
        "\n",
        "n_epoch = 3 # the number of epochs\n",
        "n_batch = 32 # the number of batches"
      ],
      "metadata": {
        "id": "XGXKm0pHhnoO"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loader 설정하기\n",
        "train_loader = torch.utils.data.DataLoader(training_data, batch_size=n_batch, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=n_batch, shuffle=True)"
      ],
      "metadata": {
        "id": "s3viP29EipLg"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_epoch):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "        # input data 가져오기\n",
        "        # data 는 [inputs, labels]로 구성된 리스트\n",
        "        inputs, labels = data\n",
        "\n",
        "        # optimizer의 파라미터 gradient를 0으로 설정\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #############################################\n",
        "        ################### 문제 2-3 #################\n",
        "        # forward, backward, optimize \n",
        "        #############################################\n",
        "          # 코드 작성\n",
        "        inputs.to(device)\n",
        "        labels.to(device)\n",
        "        # data를 GPU나 CPU에 보낸다.\n",
        "        output = model(inputs)\n",
        "        # 모델에서 output을 뽑아낸다.\n",
        "        loss = nn.functional.nll_loss(output, labels)\n",
        "        #nll loss를 구한다.\n",
        "        loss.backward()\n",
        "        #back propagation 수행\n",
        "        optimizer.step()\n",
        "        #optimize를 수행한다.\n",
        "\n",
        "        #############################################\n",
        "\n",
        "        # loss 출력\n",
        "        running_loss += loss.item()\n",
        "        if i % n_batch == 0:    # print every n_batch mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / n_batch:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "m6ByMb4whKFt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b64cf490-47fe-4273-b99f-aa22c4e53767"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,     1] loss: 0.073\n",
            "[1,    33] loss: 2.307\n",
            "[1,    65] loss: 2.306\n",
            "[1,    97] loss: 2.303\n",
            "[1,   129] loss: 2.300\n",
            "[1,   161] loss: 2.293\n",
            "[1,   193] loss: 2.297\n",
            "[1,   225] loss: 2.295\n",
            "[1,   257] loss: 2.292\n",
            "[1,   289] loss: 2.289\n",
            "[1,   321] loss: 2.283\n",
            "[1,   353] loss: 2.284\n",
            "[1,   385] loss: 2.274\n",
            "[1,   417] loss: 2.274\n",
            "[1,   449] loss: 2.271\n",
            "[1,   481] loss: 2.266\n",
            "[1,   513] loss: 2.257\n",
            "[1,   545] loss: 2.254\n",
            "[1,   577] loss: 2.247\n",
            "[1,   609] loss: 2.237\n",
            "[1,   641] loss: 2.227\n",
            "[1,   673] loss: 2.216\n",
            "[1,   705] loss: 2.200\n",
            "[1,   737] loss: 2.189\n",
            "[1,   769] loss: 2.173\n",
            "[1,   801] loss: 2.149\n",
            "[1,   833] loss: 2.119\n",
            "[1,   865] loss: 2.095\n",
            "[1,   897] loss: 2.058\n",
            "[1,   929] loss: 2.018\n",
            "[1,   961] loss: 1.967\n",
            "[1,   993] loss: 1.912\n",
            "[1,  1025] loss: 1.869\n",
            "[1,  1057] loss: 1.785\n",
            "[1,  1089] loss: 1.761\n",
            "[1,  1121] loss: 1.655\n",
            "[1,  1153] loss: 1.600\n",
            "[1,  1185] loss: 1.527\n",
            "[1,  1217] loss: 1.441\n",
            "[1,  1249] loss: 1.374\n",
            "[1,  1281] loss: 1.267\n",
            "[1,  1313] loss: 1.222\n",
            "[1,  1345] loss: 1.144\n",
            "[1,  1377] loss: 1.138\n",
            "[1,  1409] loss: 1.062\n",
            "[1,  1441] loss: 0.961\n",
            "[1,  1473] loss: 0.927\n",
            "[1,  1505] loss: 0.874\n",
            "[1,  1537] loss: 0.873\n",
            "[1,  1569] loss: 0.833\n",
            "[1,  1601] loss: 0.797\n",
            "[1,  1633] loss: 0.749\n",
            "[1,  1665] loss: 0.763\n",
            "[1,  1697] loss: 0.697\n",
            "[1,  1729] loss: 0.684\n",
            "[1,  1761] loss: 0.711\n",
            "[1,  1793] loss: 0.683\n",
            "[1,  1825] loss: 0.621\n",
            "[1,  1857] loss: 0.675\n",
            "[2,     1] loss: 0.019\n",
            "[2,    33] loss: 0.596\n",
            "[2,    65] loss: 0.586\n",
            "[2,    97] loss: 0.637\n",
            "[2,   129] loss: 0.588\n",
            "[2,   161] loss: 0.554\n",
            "[2,   193] loss: 0.571\n",
            "[2,   225] loss: 0.560\n",
            "[2,   257] loss: 0.564\n",
            "[2,   289] loss: 0.557\n",
            "[2,   321] loss: 0.550\n",
            "[2,   353] loss: 0.599\n",
            "[2,   385] loss: 0.557\n",
            "[2,   417] loss: 0.540\n",
            "[2,   449] loss: 0.451\n",
            "[2,   481] loss: 0.480\n",
            "[2,   513] loss: 0.483\n",
            "[2,   545] loss: 0.549\n",
            "[2,   577] loss: 0.537\n",
            "[2,   609] loss: 0.507\n",
            "[2,   641] loss: 0.457\n",
            "[2,   673] loss: 0.468\n",
            "[2,   705] loss: 0.506\n",
            "[2,   737] loss: 0.432\n",
            "[2,   769] loss: 0.484\n",
            "[2,   801] loss: 0.510\n",
            "[2,   833] loss: 0.494\n",
            "[2,   865] loss: 0.473\n",
            "[2,   897] loss: 0.483\n",
            "[2,   929] loss: 0.480\n",
            "[2,   961] loss: 0.480\n",
            "[2,   993] loss: 0.454\n",
            "[2,  1025] loss: 0.517\n",
            "[2,  1057] loss: 0.476\n",
            "[2,  1089] loss: 0.452\n",
            "[2,  1121] loss: 0.466\n",
            "[2,  1153] loss: 0.453\n",
            "[2,  1185] loss: 0.466\n",
            "[2,  1217] loss: 0.442\n",
            "[2,  1249] loss: 0.450\n",
            "[2,  1281] loss: 0.387\n",
            "[2,  1313] loss: 0.440\n",
            "[2,  1345] loss: 0.431\n",
            "[2,  1377] loss: 0.430\n",
            "[2,  1409] loss: 0.379\n",
            "[2,  1441] loss: 0.434\n",
            "[2,  1473] loss: 0.408\n",
            "[2,  1505] loss: 0.426\n",
            "[2,  1537] loss: 0.433\n",
            "[2,  1569] loss: 0.417\n",
            "[2,  1601] loss: 0.348\n",
            "[2,  1633] loss: 0.376\n",
            "[2,  1665] loss: 0.405\n",
            "[2,  1697] loss: 0.421\n",
            "[2,  1729] loss: 0.415\n",
            "[2,  1761] loss: 0.347\n",
            "[2,  1793] loss: 0.406\n",
            "[2,  1825] loss: 0.338\n",
            "[2,  1857] loss: 0.366\n",
            "[3,     1] loss: 0.008\n",
            "[3,    33] loss: 0.348\n",
            "[3,    65] loss: 0.383\n",
            "[3,    97] loss: 0.367\n",
            "[3,   129] loss: 0.358\n",
            "[3,   161] loss: 0.320\n",
            "[3,   193] loss: 0.384\n",
            "[3,   225] loss: 0.351\n",
            "[3,   257] loss: 0.352\n",
            "[3,   289] loss: 0.342\n",
            "[3,   321] loss: 0.370\n",
            "[3,   353] loss: 0.358\n",
            "[3,   385] loss: 0.434\n",
            "[3,   417] loss: 0.360\n",
            "[3,   449] loss: 0.358\n",
            "[3,   481] loss: 0.362\n",
            "[3,   513] loss: 0.343\n",
            "[3,   545] loss: 0.323\n",
            "[3,   577] loss: 0.323\n",
            "[3,   609] loss: 0.324\n",
            "[3,   641] loss: 0.347\n",
            "[3,   673] loss: 0.404\n",
            "[3,   705] loss: 0.353\n",
            "[3,   737] loss: 0.325\n",
            "[3,   769] loss: 0.291\n",
            "[3,   801] loss: 0.357\n",
            "[3,   833] loss: 0.333\n",
            "[3,   865] loss: 0.389\n",
            "[3,   897] loss: 0.301\n",
            "[3,   929] loss: 0.319\n",
            "[3,   961] loss: 0.335\n",
            "[3,   993] loss: 0.302\n",
            "[3,  1025] loss: 0.280\n",
            "[3,  1057] loss: 0.307\n",
            "[3,  1089] loss: 0.291\n",
            "[3,  1121] loss: 0.304\n",
            "[3,  1153] loss: 0.282\n",
            "[3,  1185] loss: 0.395\n",
            "[3,  1217] loss: 0.332\n",
            "[3,  1249] loss: 0.352\n",
            "[3,  1281] loss: 0.333\n",
            "[3,  1313] loss: 0.326\n",
            "[3,  1345] loss: 0.353\n",
            "[3,  1377] loss: 0.276\n",
            "[3,  1409] loss: 0.301\n",
            "[3,  1441] loss: 0.338\n",
            "[3,  1473] loss: 0.351\n",
            "[3,  1505] loss: 0.363\n",
            "[3,  1537] loss: 0.352\n",
            "[3,  1569] loss: 0.301\n",
            "[3,  1601] loss: 0.291\n",
            "[3,  1633] loss: 0.340\n",
            "[3,  1665] loss: 0.297\n",
            "[3,  1697] loss: 0.288\n",
            "[3,  1729] loss: 0.320\n",
            "[3,  1761] loss: 0.295\n",
            "[3,  1793] loss: 0.290\n",
            "[3,  1825] loss: 0.276\n",
            "[3,  1857] loss: 0.337\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Test the Network**"
      ],
      "metadata": {
        "id": "XnqNJjGki4JZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test feature와 label을 test_loader로부터 가져오기\n",
        "test_features, test_labels = next(iter(test_loader))\n",
        "print(f\"Feature batch shape: {test_features.size()}\")\n",
        "print(f\"Labels batch shape: {test_labels.size()}\")"
      ],
      "metadata": {
        "id": "CO1AMDEAjGrK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "846e3ac7-1ca4-4a1d-8e6a-9fd4a2cb3b98"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([32, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1개 이미지 확인해보기\n",
        "\n",
        "logits = model(test_features[0]) # 일부 백그라운드 연산들과 함께 모델의 forward 를 실행 \n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "\n",
        "\n",
        "img = test_features[0].squeeze()\n",
        "label = test_labels[0]\n",
        "\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Predicted class: {y_pred}\")\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "id": "bgC3vITkjWdU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "c467a388-187b-4de4-9757-0b058c3c8315"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([5])\n",
            "Label: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 test data에 대한 결과 확인\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad(): # 모델을 학습하는 것이 아니므로 gradient 계산을 할 필요가 없음\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the test images: {100 * correct // total} %')"
      ],
      "metadata": {
        "id": "RE_tglcsmmRD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09fca170-4ce3-4139-991b-3a8c80d66c66"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 91 %\n"
          ]
        }
      ]
    }
  ]
}